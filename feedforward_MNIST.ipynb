{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "import torch.utils.data as D\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "DEVICE = \"cuda:0\"\n",
    "DTYPE = torch.bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(x):\n",
    "    x = to_tensor(x)\n",
    "    x = x.to(device=DEVICE, dtype=DTYPE)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = torchvision.datasets.MNIST(\"./MNIST\",\n",
    "                                        transform=transform,\n",
    "                                        train=True,\n",
    "                                        download=True)\n",
    "\n",
    "mnist_test = torchvision.datasets.MNIST(\"./MNIST\",\n",
    "                                        transform=transform,\n",
    "                                        train=False,\n",
    "                                        download=True)\n",
    "                                        \n",
    "\n",
    "combined = mnist_train + mnist_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_gen = torch.Generator().manual_seed(192)\n",
    "train, val, test = D.random_split(combined, [0.8, 0.1, 0.1], generator=rand_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = D.DataLoader(train, 128, shuffle=True)\n",
    "val_loader = D.DataLoader(val, 128)\n",
    "test_loader = D.DataLoader(test, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = torch.prod(torch.tensor(combined[0][0].shape)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 output_dim: int):\n",
    "        super().__init__()\n",
    "        self._input_dim = input_dim\n",
    "        self._output_dim = output_dim\n",
    "        \n",
    "        self._net = nn.Sequential(\n",
    "            nn.Flatten(start_dim=1, end_dim=-1),\n",
    "            nn.Linear(input_dim, 200),\n",
    "            nn.ReLU(False),\n",
    "            #nn.BatchNorm1d(200),\n",
    "            nn.Linear(200, 100),\n",
    "            nn.ReLU(False),\n",
    "            #nn.BatchNorm1d(100),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.ReLU(False),\n",
    "            #nn.BatchNorm1d(50),\n",
    "            nn.Linear(50, output_dim),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self._net(x)\n",
    "    \n",
    "    #@torch.inference_mode()\n",
    "    #def predict(self, x):\n",
    "        #return self._net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "from IPython.display import clear_output\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "\n",
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: D.DataLoader,\n",
    "    val_loader: D.DataLoader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    epochs=100):\n",
    "    \n",
    "    mca = MulticlassAccuracy(10).to(device=DEVICE)\n",
    "    \n",
    "    history = {\"train\":[], \"val\":[]}\n",
    "    num_train_batches = ceil(len(train_loader.dataset) / train_loader.batch_size)\n",
    "    num_val_batches = ceil(len(val_loader.dataset) / val_loader.batch_size)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        avg_train_loss = 0\n",
    "        avg_train_acc = 0\n",
    "        \n",
    "        for step, (train_batch, train_labels) in enumerate(train_loader):\n",
    "            # Forward\n",
    "            preds = model(train_batch)\n",
    "            targets = F.one_hot(train_labels).to(device=DEVICE, dtype=DTYPE)\n",
    "            \n",
    "            # Compute Metrics\n",
    "            train_loss = criterion(preds, targets)\n",
    "            print(train_labels.device)\n",
    "            with torch.inference_mode():\n",
    "                train_acc = mca(preds, train_labels)\n",
    "                avg_train_loss += train_loss.item()\n",
    "                avg_train_acc += train_acc.item()\n",
    "\n",
    "            #Make output\n",
    "            #\n",
    "            #num_bars = int(((step / num_train_batches) * 20)) + 1\n",
    "            #completion_string = \"=\"*num_bars\n",
    "            #completion_string += \"-\"*(20 - num_bars)\n",
    "            completion_string = \"$\"\n",
    "            print(\n",
    "                \"Epoch: {} \\t [{}] \\t Train loss: {} \\t Train acc: {}\"\\\n",
    "                .format(epoch,\n",
    "                        completion_string,\n",
    "                        train_loss,\n",
    "                        train_acc\n",
    "                        ),\n",
    "                end=\"\\r\"\n",
    "                )\n",
    "            \n",
    "            # Backpropogate\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    " \n",
    "        # Validation\n",
    "        with torch.inference_mode():\n",
    "            avg_val_loss = 0\n",
    "            for _, (val_batch, val_labels) in enumerate(val_loader):\n",
    "                val_loss = criterion(\n",
    "                    model.forward(val_batch),\n",
    "                    F.one_hot(val_labels, model._output_dim).to(device=\"cuda:0\", dtype=DTYPE)\n",
    "                    )\n",
    "                avg_val_loss += val_loss\n",
    "            \n",
    "            avg_val_loss /= num_val_batches\n",
    "            print(\"\\nAvg Val loss: {:.3f}\".format(avg_val_loss))\n",
    "\n",
    "        # Record\n",
    "        avg_train_loss /= num_train_batches\n",
    "        avg_train_acc /= num_train_batches\n",
    "        history[\"train\"].append(avg_train_loss)\n",
    "        history[\"val\"].append(avg_val_loss)\n",
    "        \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Encountered different devices in metric calculation (see stacktrace for details). This could be due to the metric class not being on the same device as input. Instead of `metric=MulticlassAccuracy(...)` try to do `metric=MulticlassAccuracy(...).to(device)` where device corresponds to the device of the input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchmetrics\\metric.py:390\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 390\u001b[0m     update(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    391\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchmetrics\\classification\\stat_scores.py:319\u001b[0m, in \u001b[0;36mMulticlassStatScores.update\u001b[1;34m(self, preds, target)\u001b[0m\n\u001b[0;32m    318\u001b[0m preds, target \u001b[39m=\u001b[39m _multiclass_stat_scores_format(preds, target, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtop_k)\n\u001b[1;32m--> 319\u001b[0m tp, fp, tn, fn \u001b[39m=\u001b[39m _multiclass_stat_scores_update(\n\u001b[0;32m    320\u001b[0m     preds, target, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_classes, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtop_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maverage, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmultidim_average, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index\n\u001b[0;32m    321\u001b[0m )\n\u001b[0;32m    322\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_state(tp, fp, tn, fn)\n",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchmetrics\\functional\\classification\\stat_scores.py:412\u001b[0m, in \u001b[0;36m_multiclass_stat_scores_update\u001b[1;34m(preds, target, num_classes, top_k, average, multidim_average, ignore_index)\u001b[0m\n\u001b[0;32m    411\u001b[0m     target \u001b[39m=\u001b[39m target[idx]\n\u001b[1;32m--> 412\u001b[0m unique_mapping \u001b[39m=\u001b[39m target\u001b[39m.\u001b[39;49mto(torch\u001b[39m.\u001b[39;49mlong) \u001b[39m*\u001b[39;49m num_classes \u001b[39m+\u001b[39;49m preds\u001b[39m.\u001b[39;49mto(torch\u001b[39m.\u001b[39;49mlong)\n\u001b[0;32m    413\u001b[0m bins \u001b[39m=\u001b[39m _bincount(unique_mapping, minlength\u001b[39m=\u001b[39mnum_classes\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kyle\\Documents\\GitHub\\GPTRec\\torch_exper.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/GPTRec/torch_exper.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/GPTRec/torch_exper.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m criterion \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mCrossEntropyLoss(reduction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/GPTRec/torch_exper.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m hist \u001b[39m=\u001b[39m train_model(model,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/GPTRec/torch_exper.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                    train_loader,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/GPTRec/torch_exper.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                    val_loader,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/GPTRec/torch_exper.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                    optimizer,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/GPTRec/torch_exper.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                    criterion,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/GPTRec/torch_exper.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m                    epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\kyle\\Documents\\GitHub\\GPTRec\\torch_exper.ipynb Cell 10\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, optimizer, criterion, epochs)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/GPTRec/torch_exper.ipynb#W1sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mprint\u001b[39m(train_labels\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/GPTRec/torch_exper.ipynb#W1sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39minference_mode():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/GPTRec/torch_exper.ipynb#W1sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     train_acc \u001b[39m=\u001b[39m mca(preds, train_labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/GPTRec/torch_exper.ipynb#W1sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     avg_train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m train_loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/GPTRec/torch_exper.ipynb#W1sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     avg_train_acc \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m train_acc\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchmetrics\\metric.py:236\u001b[0m, in \u001b[0;36mMetric.forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_full_state_update(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    235\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 236\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_reduce_state_update(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    238\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_cache\n",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchmetrics\\metric.py:302\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_grad \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m  \u001b[39m# allow grads for batch computation\u001b[39;00m\n\u001b[0;32m    301\u001b[0m \u001b[39m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[1;32m--> 302\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    303\u001b[0m batch_val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute()\n\u001b[0;32m    305\u001b[0m \u001b[39m# reduce batch and global state\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchmetrics\\metric.py:393\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    392\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mExpected all tensors to be on\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(err):\n\u001b[1;32m--> 393\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    394\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mEncountered different devices in metric calculation (see stacktrace for details).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    395\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m This could be due to the metric class not being on the same device as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    396\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Instead of `metric=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m(...)` try to do\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    397\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m `metric=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m(...).to(device)` where\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    398\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m device corresponds to the device of the input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m             ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m    400\u001b[0m         \u001b[39mraise\u001b[39;00m err\n\u001b[0;32m    402\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_on_cpu:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Encountered different devices in metric calculation (see stacktrace for details). This could be due to the metric class not being on the same device as input. Instead of `metric=MulticlassAccuracy(...)` try to do `metric=MulticlassAccuracy(...).to(device)` where device corresponds to the device of the input."
     ]
    }
   ],
   "source": [
    "model = Model(INPUT_SHAPE, 10)\n",
    "model.to(device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "\n",
    "hist = train_model(model,\n",
    "                   train_loader,\n",
    "                   val_loader,\n",
    "                   optimizer,\n",
    "                   criterion,\n",
    "                   epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7239, device='cuda:0')\n",
      "tensor(0.7289, device='cuda:0')\n",
      "tensor(0.6800, device='cuda:0')\n",
      "tensor(0.7679, device='cuda:0')\n",
      "tensor(0.6963, device='cuda:0')\n",
      "tensor(0.7662, device='cuda:0')\n",
      "tensor(0.7713, device='cuda:0')\n",
      "tensor(0.6979, device='cuda:0')\n",
      "tensor(0.7642, device='cuda:0')\n",
      "tensor(0.7395, device='cuda:0')\n",
      "tensor(0.7269, device='cuda:0')\n",
      "tensor(0.7515, device='cuda:0')\n",
      "tensor(0.7302, device='cuda:0')\n",
      "tensor(0.7048, device='cuda:0')\n",
      "tensor(0.7585, device='cuda:0')\n",
      "tensor(0.7291, device='cuda:0')\n",
      "tensor(0.7104, device='cuda:0')\n",
      "tensor(0.7161, device='cuda:0')\n",
      "tensor(0.7446, device='cuda:0')\n",
      "tensor(0.6651, device='cuda:0')\n",
      "tensor(0.7314, device='cuda:0')\n",
      "tensor(0.7222, device='cuda:0')\n",
      "tensor(0.7402, device='cuda:0')\n",
      "tensor(0.7448, device='cuda:0')\n",
      "tensor(0.7256, device='cuda:0')\n",
      "tensor(0.6812, device='cuda:0')\n",
      "tensor(0.6981, device='cuda:0')\n",
      "tensor(0.7429, device='cuda:0')\n",
      "tensor(0.6393, device='cuda:0')\n",
      "tensor(0.7467, device='cuda:0')\n",
      "tensor(0.7316, device='cuda:0')\n",
      "tensor(0.7196, device='cuda:0')\n",
      "tensor(0.7170, device='cuda:0')\n",
      "tensor(0.7250, device='cuda:0')\n",
      "tensor(0.7589, device='cuda:0')\n",
      "tensor(0.7279, device='cuda:0')\n",
      "tensor(0.7056, device='cuda:0')\n",
      "tensor(0.6997, device='cuda:0')\n",
      "tensor(0.7241, device='cuda:0')\n",
      "tensor(0.6937, device='cuda:0')\n",
      "tensor(0.7457, device='cuda:0')\n",
      "tensor(0.7017, device='cuda:0')\n",
      "tensor(0.7296, device='cuda:0')\n",
      "tensor(0.7324, device='cuda:0')\n",
      "tensor(0.7096, device='cuda:0')\n",
      "tensor(0.7633, device='cuda:0')\n",
      "tensor(0.7741, device='cuda:0')\n",
      "tensor(0.7253, device='cuda:0')\n",
      "tensor(0.7353, device='cuda:0')\n",
      "tensor(0.7579, device='cuda:0')\n",
      "tensor(0.7301, device='cuda:0')\n",
      "tensor(0.7269, device='cuda:0')\n",
      "tensor(0.7218, device='cuda:0')\n",
      "tensor(0.7063, device='cuda:0')\n",
      "tensor(0.7186, device='cuda:0')\n",
      "tensor(0.7278, device='cuda:0')\n",
      "tensor(0.7360, device='cuda:0')\n",
      "tensor(0.7134, device='cuda:0')\n",
      "tensor(0.7428, device='cuda:0')\n",
      "tensor(0.7152, device='cuda:0')\n",
      "tensor(0.7339, device='cuda:0')\n",
      "tensor(0.7157, device='cuda:0')\n",
      "tensor(0.7619, device='cuda:0')\n",
      "tensor(0.7232, device='cuda:0')\n",
      "tensor(0.7278, device='cuda:0')\n",
      "tensor(0.7084, device='cuda:0')\n",
      "tensor(0.7339, device='cuda:0')\n",
      "tensor(0.7293, device='cuda:0')\n",
      "tensor(0.7092, device='cuda:0')\n",
      "tensor(0.7024, device='cuda:0')\n",
      "tensor(0.7421, device='cuda:0')\n",
      "tensor(0.7172, device='cuda:0')\n",
      "tensor(0.7178, device='cuda:0')\n",
      "tensor(0.7303, device='cuda:0')\n",
      "tensor(0.7569, device='cuda:0')\n",
      "tensor(0.7650, device='cuda:0')\n",
      "tensor(0.7142, device='cuda:0')\n",
      "tensor(0.7335, device='cuda:0')\n",
      "tensor(0.6986, device='cuda:0')\n",
      "tensor(0.7460, device='cuda:0')\n",
      "tensor(0.7097, device='cuda:0')\n",
      "tensor(0.7555, device='cuda:0')\n",
      "tensor(0.7434, device='cuda:0')\n",
      "tensor(0.7669, device='cuda:0')\n",
      "tensor(0.7324, device='cuda:0')\n",
      "tensor(0.7414, device='cuda:0')\n",
      "tensor(0.7139, device='cuda:0')\n",
      "tensor(0.7465, device='cuda:0')\n",
      "tensor(0.6873, device='cuda:0')\n",
      "tensor(0.7081, device='cuda:0')\n",
      "tensor(0.7505, device='cuda:0')\n",
      "tensor(0.7123, device='cuda:0')\n",
      "tensor(0.7460, device='cuda:0')\n",
      "tensor(0.7309, device='cuda:0')\n",
      "tensor(0.7264, device='cuda:0')\n",
      "tensor(0.7172, device='cuda:0')\n",
      "tensor(0.7650, device='cuda:0')\n",
      "tensor(0.7338, device='cuda:0')\n",
      "tensor(0.7213, device='cuda:0')\n",
      "tensor(0.7000, device='cuda:0')\n",
      "tensor(0.7148, device='cuda:0')\n",
      "tensor(0.7465, device='cuda:0')\n",
      "tensor(0.6969, device='cuda:0')\n",
      "tensor(0.6810, device='cuda:0')\n",
      "tensor(0.7116, device='cuda:0')\n",
      "tensor(0.7650, device='cuda:0')\n",
      "tensor(0.7208, device='cuda:0')\n",
      "tensor(0.7067, device='cuda:0')\n",
      "tensor(0.7045, device='cuda:0')\n",
      "tensor(0.7429, device='cuda:0')\n",
      "tensor(0.7411, device='cuda:0')\n",
      "tensor(0.7416, device='cuda:0')\n",
      "tensor(0.7319, device='cuda:0')\n",
      "tensor(0.7436, device='cuda:0')\n",
      "tensor(0.7474, device='cuda:0')\n",
      "tensor(0.7281, device='cuda:0')\n",
      "tensor(0.7475, device='cuda:0')\n",
      "tensor(0.7652, device='cuda:0')\n",
      "tensor(0.7429, device='cuda:0')\n",
      "tensor(0.7546, device='cuda:0')\n",
      "tensor(0.6458, device='cuda:0')\n",
      "tensor(0.7331, device='cuda:0')\n",
      "tensor(0.7248, device='cuda:0')\n",
      "tensor(0.7805, device='cuda:0')\n",
      "tensor(0.7444, device='cuda:0')\n",
      "tensor(0.7236, device='cuda:0')\n",
      "tensor(0.7331, device='cuda:0')\n",
      "tensor(0.7155, device='cuda:0')\n",
      "tensor(0.7448, device='cuda:0')\n",
      "tensor(0.7044, device='cuda:0')\n",
      "tensor(0.7397, device='cuda:0')\n",
      "tensor(0.7322, device='cuda:0')\n",
      "tensor(0.7460, device='cuda:0')\n",
      "tensor(0.7297, device='cuda:0')\n",
      "tensor(0.7747, device='cuda:0')\n",
      "tensor(0.6927, device='cuda:0')\n",
      "tensor(0.7811, device='cuda:0')\n",
      "tensor(0.7161, device='cuda:0')\n",
      "tensor(0.7358, device='cuda:0')\n",
      "tensor(0.7190, device='cuda:0')\n",
      "tensor(0.7191, device='cuda:0')\n",
      "tensor(0.7426, device='cuda:0')\n",
      "tensor(0.7310, device='cuda:0')\n",
      "tensor(0.7602, device='cuda:0')\n",
      "tensor(0.7542, device='cuda:0')\n",
      "tensor(0.7546, device='cuda:0')\n",
      "tensor(0.7308, device='cuda:0')\n",
      "tensor(0.7293, device='cuda:0')\n",
      "tensor(0.7322, device='cuda:0')\n",
      "tensor(0.7318, device='cuda:0')\n",
      "tensor(0.6695, device='cuda:0')\n",
      "tensor(0.7224, device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kyle\\Documents\\GitHub\\GPTRec\\torch_exper.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/GPTRec/torch_exper.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/GPTRec/torch_exper.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m mca \u001b[39m=\u001b[39m MulticlassAccuracy(\u001b[39m10\u001b[39m)\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mDEVICE)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/GPTRec/torch_exper.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (img, label) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/GPTRec/torch_exper.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     pred \u001b[39m=\u001b[39m model(img)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/GPTRec/torch_exper.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(mca(pred, label\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mDEVICE)))\n",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataset.py:295\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    294\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[1;32m--> 295\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataset.py:240\u001b[0m, in \u001b[0;36mConcatDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     sample_idx \u001b[39m=\u001b[39m idx \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcumulative_sizes[dataset_idx \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[1;32m--> 240\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdatasets[dataset_idx][sample_idx]\n",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[0;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "\u001b[1;32mc:\\Users\\kyle\\Documents\\GitHub\\GPTRec\\torch_exper.ipynb Cell 11\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/GPTRec/torch_exper.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(x):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/GPTRec/torch_exper.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     x \u001b[39m=\u001b[39m to_tensor(x)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/GPTRec/torch_exper.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mto(device\u001b[39m=\u001b[39;49mDEVICE, dtype\u001b[39m=\u001b[39;49mDTYPE)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/GPTRec/torch_exper.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "mca = MulticlassAccuracy(10).to(device=DEVICE)\n",
    "\n",
    "for i, (img, label) in enumerate(train_loader):\n",
    "    pred = model(img)\n",
    "    print(mca(pred, label.to(device=DEVICE)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.cross_entropy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
