{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "import torch.utils.data as D\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "DEVICE = \"cuda:0\"\n",
    "DTYPE = torch.bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(x):\n",
    "    x = to_tensor(x)\n",
    "    x = x.to(device=DEVICE, dtype=DTYPE)\n",
    "    return x\n",
    "\n",
    "def target_transform(y):\n",
    "    y = torch.tensor(y).long()\n",
    "    y = F.one_hot(y, num_classes=10)\n",
    "    y = y.to(device=DEVICE, dtype=DTYPE)\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = torchvision.datasets.MNIST(\"./MNIST\",\n",
    "                                        transform=transform,\n",
    "                                        target_transform=target_transform,\n",
    "                                        train=True,\n",
    "                                        download=True)\n",
    "\n",
    "mnist_test = torchvision.datasets.MNIST(\"./MNIST\",\n",
    "                                        transform=transform,\n",
    "                                        target_transform=target_transform,\n",
    "                                        train=False,\n",
    "                                        download=True)\n",
    "                                        \n",
    "\n",
    "combined = mnist_train + mnist_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_gen = torch.Generator().manual_seed(192)\n",
    "train, val, test = D.random_split(combined, [0.8, 0.1, 0.1], generator=rand_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = D.DataLoader(train, 512, shuffle=True)\n",
    "val_loader = D.DataLoader(val, 512)\n",
    "test_loader = D.DataLoader(test, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = torch.prod(torch.tensor(combined[0][0].shape)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 output_dim: int):\n",
    "        super().__init__()\n",
    "        self._input_dim = input_dim\n",
    "        self._output_dim = output_dim\n",
    "        self._flatten = nn.Flatten(start_dim=1, end_dim=-1)\n",
    "    \n",
    "        self._linear_stack = nn.Sequential(\n",
    "            nn.Linear(input_dim, 200),\n",
    "            nn.ReLU(False),\n",
    "            nn.BatchNorm1d(200),\n",
    "            nn.Linear(200, 100),\n",
    "            nn.ReLU(False),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.ReLU(False),\n",
    "            nn.BatchNorm1d(50),\n",
    "            nn.Linear(50, output_dim),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_ = self._flatten(x)\n",
    "        return self._linear_stack(x_)\n",
    "    \n",
    "    #@torch.inference_mode()\n",
    "    #def predict(self, x):\n",
    "        #return self._net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def compute_acc(pred, target) -> float:\n",
    "    pred_= pred.clone()\n",
    "    target_ = target.clone()\n",
    "    \n",
    "    if pred_.shape[1] > 1:\n",
    "        pred_ = torch.argmax(pred_, dim=1)\n",
    "    if target_.shape[1] > 1:\n",
    "        target_ = torch.argmax(target_, dim=1)\n",
    "        \n",
    "    diff = pred_ - target_\n",
    "    missclass = torch.nonzero(diff)\n",
    "    \n",
    "    return 1 - (len(missclass) / len(pred_))\n",
    "\n",
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: D.DataLoader,\n",
    "    val_loader: D.DataLoader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    epochs=100):\n",
    "    \n",
    "    history = {\"train\":[], \"val\":[]}\n",
    "    num_train_batches = ceil(len(train_loader.dataset) / train_loader.batch_size)\n",
    "    num_val_batches = ceil(len(val_loader.dataset) / val_loader.batch_size)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        avg_train_loss = 0\n",
    "        avg_train_acc = 0\n",
    "        for step, (train_batch, train_labels) in enumerate(train_loader):\n",
    "            ###########\n",
    "            # Forward #\n",
    "            ###########\n",
    "            model.train()\n",
    "            preds = model(train_batch)\n",
    "            \n",
    "            ###################          \n",
    "            # Compute Metrics #\n",
    "            ###################\n",
    "            train_loss = criterion(preds, train_labels)\n",
    "            model.eval()\n",
    "            with torch.inference_mode():\n",
    "                train_acc = compute_acc(preds, train_labels)\n",
    "                avg_train_loss += train_loss.item()\n",
    "                avg_train_acc += train_acc\n",
    "                \n",
    "            ###############\n",
    "            # Make output #\n",
    "            ###############\n",
    "            num_bars = int(((step / num_train_batches) * 20)) + 1\n",
    "            completion_string = \"=\"*num_bars\n",
    "            completion_string += \"-\"*(20 - num_bars)\n",
    "            output = \"Epoch: {} \\t [{}] \\t Train loss: {} \\t Train acc: {}\"\\\n",
    "                .format(epoch,\n",
    "                        completion_string,\n",
    "                        train_loss,\n",
    "                        train_acc\n",
    "                        )\n",
    "            print(output, end=\"\\r\")\n",
    "            \n",
    "            #################\n",
    "            # Backpropogate #\n",
    "            #################\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        ##############\n",
    "        # Validation #\n",
    "        ##############\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            avg_val_loss = 0\n",
    "            avg_val_acc = 0 \n",
    "            for _, (val_batch, val_labels) in enumerate(val_loader):\n",
    "                preds = model(val_batch)\n",
    "                targets = val_labels\n",
    "                \n",
    "                val_loss = criterion(preds, targets)\n",
    "                avg_val_loss += val_loss\n",
    "                \n",
    "                val_acc = compute_acc(preds, targets)\n",
    "                avg_val_acc += val_acc\n",
    "            \n",
    "            avg_train_loss /= num_train_batches\n",
    "            avg_val_loss /= num_val_batches\n",
    "            print(\"\\nAvg Train Loss: {:.3f} \\t Avg Val loss: {:.3f}\".format(avg_train_loss, avg_val_loss))\n",
    "            print(\"-\"*len(output), \"\\n\")\n",
    "            \n",
    "        ##########\n",
    "        # Record #\n",
    "        ##########\n",
    "        history[\"train\"].append(avg_train_loss)\n",
    "        history[\"val\"].append(avg_val_loss)\n",
    "        \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t [====================] \t Train loss: 1.5 \t Train acc: 0.9583333333333334\n",
      "Avg Train Loss: 1.556 \t Avg Val loss: 1.508\n",
      "----------------------------------------------------------------------------------- \n",
      "\n",
      "Epoch: 1 \t [====================] \t Train loss: 1.5 \t Train acc: 0.9583333333333334\n",
      "Avg Train Loss: 1.502 \t Avg Val loss: 1.500\n",
      "----------------------------------------------------------------------------------- \n",
      "\n",
      "Epoch: 2 \t [====================] \t Train loss: 1.5 \t Train acc: 0.968759765625875\n",
      "Avg Train Loss: 1.492 \t Avg Val loss: 1.500\n",
      "------------------------------------------------------------------------ \n",
      "\n",
      "Epoch: 3 \t [====================] \t Train loss: 1.46875 \t Train acc: 0.9947916666666666\n",
      "Avg Train Loss: 1.486 \t Avg Val loss: 1.500\n",
      "--------------------------------------------------------------------------------------- \n",
      "\n",
      "Epoch: 4 \t [====================] \t Train loss: 1.4765625 \t Train acc: 0.984375255\n",
      "Avg Train Loss: 1.485 \t Avg Val loss: 1.492\n",
      "------------------------------------------------------------------------------- \n",
      "\n",
      "Epoch: 5 \t [====================] \t Train loss: 1.4765625 \t Train acc: 0.9895833333333334\n",
      "Avg Train Loss: 1.484 \t Avg Val loss: 1.492\n",
      "----------------------------------------------------------------------------------------- \n",
      "\n",
      "Epoch: 6 \t [====================] \t Train loss: 1.4765625 \t Train acc: 0.9791666666666666\n",
      "Avg Train Loss: 1.481 \t Avg Val loss: 1.492\n",
      "----------------------------------------------------------------------------------------- \n",
      "\n",
      "Epoch: 7 \t [====================] \t Train loss: 1.4765625 \t Train acc: 0.9791666666666666\n",
      "Avg Train Loss: 1.478 \t Avg Val loss: 1.492\n",
      "----------------------------------------------------------------------------------------- \n",
      "\n",
      "Epoch: 8 \t [====================] \t Train loss: 1.4921875 \t Train acc: 0.9739583333333334\n",
      "Avg Train Loss: 1.477 \t Avg Val loss: 1.492\n",
      "----------------------------------------------------------------------------------------- \n",
      "\n",
      "Epoch: 9 \t [====================] \t Train loss: 1.4921875 \t Train acc: 0.9791666666666666\n",
      "Avg Train Loss: 1.475 \t Avg Val loss: 1.492\n",
      "----------------------------------------------------------------------------------------- \n",
      "\n",
      "Epoch: 10 \t [====================] \t Train loss: 1.4609375 \t Train acc: 1.018758755\n",
      "Avg Train Loss: 1.474 \t Avg Val loss: 1.492\n",
      "--------------------------------------------------------------------------- \n",
      "\n",
      "Epoch: 11 \t [====================] \t Train loss: 1.4921875 \t Train acc: 0.9739583333333334\n",
      "Avg Train Loss: 1.473 \t Avg Val loss: 1.492\n",
      "------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch: 12 \t [=====---------------] \t Train loss: 1.4609375 \t Train acc: 0.998046875\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kyle\\Documents\\GitHub\\VariousPyTorch\\feedforward_MNIST.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m criterion \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mCrossEntropyLoss(reduction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m hist \u001b[39m=\u001b[39m train_model(model,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                    train_loader,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                    val_loader,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                    optimizer,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                    criterion,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m                    epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\kyle\\Documents\\GitHub\\VariousPyTorch\\feedforward_MNIST.ipynb Cell 10\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, optimizer, criterion, epochs)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m avg_train_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m avg_train_acc \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mfor\u001b[39;00m step, (train_batch, train_labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39m###########\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39m# Forward #\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39m###########\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     preds \u001b[39m=\u001b[39m model(train_batch)\n",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataset.py:295\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    294\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[1;32m--> 295\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataset.py:240\u001b[0m, in \u001b[0;36mConcatDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     sample_idx \u001b[39m=\u001b[39m idx \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcumulative_sizes[dataset_idx \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[1;32m--> 240\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdatasets[dataset_idx][sample_idx]\n",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[0;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "\u001b[1;32mc:\\Users\\kyle\\Documents\\GitHub\\VariousPyTorch\\feedforward_MNIST.ipynb Cell 10\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(x):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     x \u001b[39m=\u001b[39m to_tensor(x)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mto(device\u001b[39m=\u001b[39;49mDEVICE, dtype\u001b[39m=\u001b[39;49mDTYPE)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Model(INPUT_SHAPE, 10)\n",
    "model.to(device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "\n",
    "hist = train_model(model,\n",
    "                   train_loader,\n",
    "                   val_loader,\n",
    "                   optimizer,\n",
    "                   criterion,\n",
    "                   epochs=50)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably makes more sense to update the average with each batch, and then output that instead. Otherwise it doesn't even look like we're learning anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9766, device='cuda:0')\n",
      "0.9375\n",
      "0.9375\n",
      "tensor(0.9852, device='cuda:0')\n",
      "0.9140625\n",
      "0.9140625\n",
      "tensor(0.9852, device='cuda:0')\n",
      "0.9296875\n",
      "0.9296875\n",
      "tensor(0.9844, device='cuda:0')\n",
      "0.8984375\n",
      "0.8984375\n",
      "tensor(0.9792, device='cuda:0')\n",
      "0.890625\n",
      "0.890625\n",
      "tensor(0.9896, device='cuda:0')\n",
      "0.9296875\n",
      "0.9296875\n",
      "tensor(0.9861, device='cuda:0')\n",
      "0.9609375\n",
      "0.9609375\n",
      "tensor(0.9896, device='cuda:0')\n",
      "0.9453125\n",
      "0.9453125\n",
      "tensor(0.9809, device='cuda:0')\n",
      "0.9375\n",
      "0.9375\n",
      "tensor(0.9905, device='cuda:0')\n",
      "0.9609375\n",
      "0.9609375\n",
      "tensor(0.9887, device='cuda:0')\n",
      "0.9296875\n",
      "0.9296875\n",
      "tensor(0.9931, device='cuda:0')\n",
      "0.9609375\n",
      "0.9609375\n",
      "tensor(0.9809, device='cuda:0')\n",
      "0.9296875\n",
      "0.9296875\n",
      "tensor(0.9887, device='cuda:0')\n",
      "0.96875\n",
      "0.96875\n",
      "tensor(0.9887, device='cuda:0')\n",
      "0.9453125\n",
      "0.9453125\n",
      "tensor(0.9922, device='cuda:0')\n",
      "0.9609375\n",
      "0.9609375\n",
      "tensor(0.9740, device='cuda:0')\n",
      "0.890625\n",
      "0.890625\n",
      "tensor(0.9878, device='cuda:0')\n",
      "0.9296875\n",
      "0.9296875\n",
      "tensor(0.9931, device='cuda:0')\n",
      "0.9609375\n",
      "0.9609375\n",
      "tensor(0.9852, device='cuda:0')\n",
      "0.9453125\n",
      "0.9453125\n",
      "tensor(0.9870, device='cuda:0')\n",
      "0.8984375\n",
      "0.8984375\n",
      "tensor(0.9783, device='cuda:0')\n",
      "0.9296875\n",
      "0.9296875\n",
      "tensor(0.9800, device='cuda:0')\n",
      "0.8984375\n",
      "0.8984375\n",
      "tensor(0.9896, device='cuda:0')\n",
      "0.9296875\n",
      "0.9296875\n",
      "tensor(0.9896, device='cuda:0')\n",
      "0.9609375\n",
      "0.9609375\n",
      "tensor(0.9870, device='cuda:0')\n",
      "0.9296875\n",
      "0.9296875\n",
      "tensor(0.9852, device='cuda:0')\n",
      "0.9296875\n",
      "0.9296875\n",
      "tensor(0.9922, device='cuda:0')\n",
      "0.9609375\n",
      "0.9609375\n",
      "tensor(0.9887, device='cuda:0')\n",
      "0.9296875\n",
      "0.9296875\n",
      "tensor(0.9844, device='cuda:0')\n",
      "0.9453125\n",
      "0.9453125\n",
      "tensor(0.9905, device='cuda:0')\n",
      "0.9453125\n",
      "0.9453125\n",
      "tensor(0.9896, device='cuda:0')\n",
      "0.953125\n",
      "0.953125\n",
      "tensor(0.9844, device='cuda:0')\n",
      "0.9453125\n",
      "0.9453125\n",
      "tensor(0.9896, device='cuda:0')\n",
      "0.953125\n",
      "0.953125\n",
      "tensor(0.9870, device='cuda:0')\n",
      "0.9296875\n",
      "0.9296875\n",
      "tensor(0.9826, device='cuda:0')\n",
      "0.921875\n",
      "0.921875\n",
      "tensor(0.9826, device='cuda:0')\n",
      "0.8984375\n",
      "0.8984375\n",
      "tensor(0.9913, device='cuda:0')\n",
      "0.9296875\n",
      "0.9296875\n",
      "tensor(0.9905, device='cuda:0')\n",
      "0.9453125\n",
      "0.9453125\n",
      "tensor(0.9861, device='cuda:0')\n",
      "0.90625\n",
      "0.90625\n",
      "tensor(0.9913, device='cuda:0')\n",
      "0.9453125\n",
      "0.9453125\n",
      "tensor(0.9774, device='cuda:0')\n",
      "0.921875\n",
      "0.921875\n",
      "tensor(0.9939, device='cuda:0')\n",
      "0.96875\n",
      "0.96875\n",
      "tensor(0.9861, device='cuda:0')\n",
      "0.9296875\n",
      "0.9296875\n",
      "tensor(0.9870, device='cuda:0')\n",
      "0.921875\n",
      "0.921875\n",
      "tensor(0.9844, device='cuda:0')\n",
      "0.9296875\n",
      "0.9296875\n",
      "tensor(0.9896, device='cuda:0')\n",
      "0.9296875\n",
      "0.9296875\n",
      "tensor(0.9861, device='cuda:0')\n",
      "0.9375\n",
      "0.9375\n",
      "tensor(0.9887, device='cuda:0')\n",
      "0.921875\n",
      "0.921875\n",
      "tensor(0.9896, device='cuda:0')\n",
      "0.9375\n",
      "0.9375\n",
      "tensor(0.9861, device='cuda:0')\n",
      "0.9296875\n",
      "0.9296875\n",
      "tensor(0.9939, device='cuda:0')\n",
      "0.96875\n",
      "0.96875\n",
      "tensor(0.9852, device='cuda:0')\n",
      "0.953125\n",
      "0.953125\n",
      "tensor(0.9887, device='cuda:0')\n",
      "0.9140625\n",
      "0.9140625\n",
      "tensor(0.9766, device='cuda:0')\n",
      "0.8828125\n",
      "0.8828125\n",
      "tensor(0.9818, device='cuda:0')\n",
      "0.9140625\n",
      "0.9140625\n",
      "tensor(0.9887, device='cuda:0')\n",
      "0.9453125\n",
      "0.9453125\n",
      "tensor(0.9948, device='cuda:0')\n",
      "0.984375\n",
      "0.984375\n",
      "tensor(0.9878, device='cuda:0')\n",
      "0.9375\n",
      "0.9375\n",
      "tensor(0.9887, device='cuda:0')\n",
      "0.9453125\n",
      "0.9453125\n",
      "tensor(0.9974, device='cuda:0')\n",
      "0.9921875\n",
      "0.9921875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kyle\\Documents\\GitHub\\VariousPyTorch\\feedforward_MNIST.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m mca \u001b[39m=\u001b[39m Accuracy(task\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m, num_classes\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mDEVICE)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m torch\u001b[39m.\u001b[39mmanual_seed(\u001b[39m192\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (img, label) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     pred \u001b[39m=\u001b[39m model(img)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mprint\u001b[39m(mca\u001b[39m.\u001b[39mforward(pred\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat16),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                       label\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat16)))\n",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataset.py:295\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    294\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[1;32m--> 295\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataset.py:240\u001b[0m, in \u001b[0;36mConcatDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     sample_idx \u001b[39m=\u001b[39m idx \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcumulative_sizes[dataset_idx \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[1;32m--> 240\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdatasets[dataset_idx][sample_idx]\n",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[0;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "\u001b[1;32mc:\\Users\\kyle\\Documents\\GitHub\\VariousPyTorch\\feedforward_MNIST.ipynb Cell 11\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(x):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     x \u001b[39m=\u001b[39m to_tensor(x)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mDEVICE, dtype\u001b[39m=\u001b[39mDTYPE)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kyle/Documents/GitHub/VariousPyTorch/feedforward_MNIST.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\kyle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\transforms\\functional.py:169\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    167\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mview(pic\u001b[39m.\u001b[39msize[\u001b[39m1\u001b[39m], pic\u001b[39m.\u001b[39msize[\u001b[39m0\u001b[39m], \u001b[39mlen\u001b[39m(pic\u001b[39m.\u001b[39mgetbands()))\n\u001b[0;32m    168\u001b[0m \u001b[39m# put it from HWC to CHW format\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39;49mpermute((\u001b[39m2\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m))\u001b[39m.\u001b[39mcontiguous()\n\u001b[0;32m    170\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(img, torch\u001b[39m.\u001b[39mByteTensor):\n\u001b[0;32m    171\u001b[0m     \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39mto(dtype\u001b[39m=\u001b[39mdefault_float_dtype)\u001b[39m.\u001b[39mdiv(\u001b[39m255\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from torchmetrics import Accuracy\n",
    "mca = Accuracy(task=\"multiclass\", num_classes=10, ignore_index=True).to(device=DEVICE)\n",
    "\n",
    "torch.manual_seed(192)\n",
    "for i, (img, label) in enumerate(train_loader):\n",
    "    pred = model(img)\n",
    "    print(mca.forward(pred.to(torch.float16),\n",
    "                      label.to(torch.float16)))\n",
    "    \n",
    "    print(accuracy_score(torch.argmax(pred.cpu().detach().to(torch.float16), dim=1).numpy(),\n",
    "                         torch.argmax(label.cpu().detach().to(torch.float16), dim=1).numpy()))\n",
    "    \n",
    "    print(compute_acc(pred, label))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9921875"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [2]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(torch.tensor([1, 0, 1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
